{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvcVOHBzlAeAdaaIUEXBRV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ezzaldin97/pytorch-coding/blob/main/pyTorch_DL_Training_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kOH-9T0It9cQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply gradient descent using pytorch...\n",
        "# reshape X and y to use LinearRegression Model in pyTorch\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)\n",
        "y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features; output_size = n_features"
      ],
      "metadata": {
        "id": "HjvytOrHvbi2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressor(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegressor, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, X):\n",
        "    return self.lin(X)\n",
        "model = LinearRegressor(input_size, output_size)"
      ],
      "metadata": {
        "id": "g17eOap5yZza"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "epochs = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "for _ in range(epochs):\n",
        "  y_hat = model(X)\n",
        "  print(f\"yhat: {y_hat}\")\n",
        "  l = loss(y_hat, y)\n",
        "  print(f\"loss: {l}\")\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT0PPoFsvqEx",
        "outputId": "6b0f1ef9-4890-4ef5-81f0-93ed60a9c8e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yhat: tensor([[0.0924],\n",
            "        [0.2198],\n",
            "        [0.3472],\n",
            "        [0.4746]], grad_fn=<AddmmBackward0>)\n",
            "loss: 26.628429412841797\n",
            "yhat: tensor([[0.4694],\n",
            "        [0.8794],\n",
            "        [1.2895],\n",
            "        [1.6995]], grad_fn=<AddmmBackward0>)\n",
            "loss: 18.491497039794922\n",
            "yhat: tensor([[0.7832],\n",
            "        [1.4288],\n",
            "        [2.0744],\n",
            "        [2.7199]], grad_fn=<AddmmBackward0>)\n",
            "loss: 12.84536361694336\n",
            "yhat: tensor([[1.0445],\n",
            "        [1.8863],\n",
            "        [2.7282],\n",
            "        [3.5700]], grad_fn=<AddmmBackward0>)\n",
            "loss: 8.927543640136719\n",
            "yhat: tensor([[1.2619],\n",
            "        [2.2674],\n",
            "        [3.2728],\n",
            "        [4.2782]], grad_fn=<AddmmBackward0>)\n",
            "loss: 6.2089643478393555\n",
            "yhat: tensor([[1.4429],\n",
            "        [2.5847],\n",
            "        [3.7265],\n",
            "        [4.8683]], grad_fn=<AddmmBackward0>)\n",
            "loss: 4.32251501083374\n",
            "yhat: tensor([[1.5935],\n",
            "        [2.8489],\n",
            "        [4.1044],\n",
            "        [5.3599]], grad_fn=<AddmmBackward0>)\n",
            "loss: 3.0134615898132324\n",
            "yhat: tensor([[1.7187],\n",
            "        [3.0690],\n",
            "        [4.4192],\n",
            "        [5.7695]], grad_fn=<AddmmBackward0>)\n",
            "loss: 2.105053424835205\n",
            "yhat: tensor([[1.8229],\n",
            "        [3.2522],\n",
            "        [4.6814],\n",
            "        [6.1107]], grad_fn=<AddmmBackward0>)\n",
            "loss: 1.4746439456939697\n",
            "yhat: tensor([[1.9094],\n",
            "        [3.4047],\n",
            "        [4.8999],\n",
            "        [6.3951]], grad_fn=<AddmmBackward0>)\n",
            "loss: 1.0371320247650146\n",
            "yhat: tensor([[1.9814],\n",
            "        [3.5316],\n",
            "        [5.0819],\n",
            "        [6.6321]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.7334692478179932\n",
            "yhat: tensor([[2.0412],\n",
            "        [3.6373],\n",
            "        [5.2334],\n",
            "        [6.8296]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.5226813554763794\n",
            "yhat: tensor([[2.0908],\n",
            "        [3.7253],\n",
            "        [5.3597],\n",
            "        [6.9942]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.37633761763572693\n",
            "yhat: tensor([[2.1320],\n",
            "        [3.7984],\n",
            "        [5.4649],\n",
            "        [7.1314]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.2747113108634949\n",
            "yhat: tensor([[2.1661],\n",
            "        [3.8593],\n",
            "        [5.5525],\n",
            "        [7.2458]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.2041136622428894\n",
            "yhat: tensor([[2.1943],\n",
            "        [3.9099],\n",
            "        [5.6255],\n",
            "        [7.3411]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.15504679083824158\n",
            "yhat: tensor([[2.2177],\n",
            "        [3.9520],\n",
            "        [5.6864],\n",
            "        [7.4207]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.12092015147209167\n",
            "yhat: tensor([[2.2370],\n",
            "        [3.9870],\n",
            "        [5.7370],\n",
            "        [7.4870]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.09716053307056427\n",
            "yhat: tensor([[2.2529],\n",
            "        [4.0161],\n",
            "        [5.7792],\n",
            "        [7.5424]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.08059515058994293\n",
            "yhat: tensor([[2.2660],\n",
            "        [4.0402],\n",
            "        [5.8144],\n",
            "        [7.5886]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.06902190297842026\n",
            "yhat: tensor([[2.2767],\n",
            "        [4.0602],\n",
            "        [5.8437],\n",
            "        [7.6272]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.06091306731104851\n",
            "yhat: tensor([[2.2855],\n",
            "        [4.0768],\n",
            "        [5.8681],\n",
            "        [7.6594]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.055208802223205566\n",
            "yhat: tensor([[2.2927],\n",
            "        [4.0905],\n",
            "        [5.8884],\n",
            "        [7.6863]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.05117328464984894\n",
            "yhat: tensor([[2.2984],\n",
            "        [4.1019],\n",
            "        [5.9054],\n",
            "        [7.7088]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04829617962241173\n",
            "yhat: tensor([[2.3031],\n",
            "        [4.1113],\n",
            "        [5.9195],\n",
            "        [7.7277]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04622340202331543\n",
            "yhat: tensor([[2.3068],\n",
            "        [4.1190],\n",
            "        [5.9313],\n",
            "        [7.7435]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04470919817686081\n",
            "yhat: tensor([[2.3098],\n",
            "        [4.1254],\n",
            "        [5.9411],\n",
            "        [7.7567]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04358291998505592\n",
            "yhat: tensor([[2.3120],\n",
            "        [4.1306],\n",
            "        [5.9492],\n",
            "        [7.7678]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04272628575563431\n",
            "yhat: tensor([[2.3138],\n",
            "        [4.1349],\n",
            "        [5.9561],\n",
            "        [7.7772]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04205730929970741\n",
            "yhat: tensor([[2.3151],\n",
            "        [4.1384],\n",
            "        [5.9617],\n",
            "        [7.7851]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.041518889367580414\n",
            "yhat: tensor([[2.3160],\n",
            "        [4.1412],\n",
            "        [5.9665],\n",
            "        [7.7917]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04107154905796051\n",
            "yhat: tensor([[2.3166],\n",
            "        [4.1435],\n",
            "        [5.9704],\n",
            "        [7.7974]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.040687743574380875\n",
            "yhat: tensor([[2.3169],\n",
            "        [4.1453],\n",
            "        [5.9737],\n",
            "        [7.8021]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04034867882728577\n",
            "yhat: tensor([[2.3170],\n",
            "        [4.1468],\n",
            "        [5.9765],\n",
            "        [7.8062]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.04004088044166565\n",
            "yhat: tensor([[2.3170],\n",
            "        [4.1479],\n",
            "        [5.9788],\n",
            "        [7.8097]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03975537419319153\n",
            "yhat: tensor([[2.3168],\n",
            "        [4.1487],\n",
            "        [5.9807],\n",
            "        [7.8126]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.039485618472099304\n",
            "yhat: tensor([[2.3164],\n",
            "        [4.1494],\n",
            "        [5.9823],\n",
            "        [7.8152]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03922729566693306\n",
            "yhat: tensor([[2.3160],\n",
            "        [4.1498],\n",
            "        [5.9836],\n",
            "        [7.8174]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03897738829255104\n",
            "yhat: tensor([[2.3155],\n",
            "        [4.1501],\n",
            "        [5.9848],\n",
            "        [7.8194]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03873363882303238\n",
            "yhat: tensor([[2.3149],\n",
            "        [4.1503],\n",
            "        [5.9857],\n",
            "        [7.8211]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.038494646549224854\n",
            "yhat: tensor([[2.3143],\n",
            "        [4.1504],\n",
            "        [5.9865],\n",
            "        [7.8226]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03825933858752251\n",
            "yhat: tensor([[2.3136],\n",
            "        [4.1504],\n",
            "        [5.9871],\n",
            "        [7.8239]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03802701458334923\n",
            "yhat: tensor([[2.3128],\n",
            "        [4.1503],\n",
            "        [5.9877],\n",
            "        [7.8251]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03779716417193413\n",
            "yhat: tensor([[2.3121],\n",
            "        [4.1501],\n",
            "        [5.9882],\n",
            "        [7.8262]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03756944462656975\n",
            "yhat: tensor([[2.3113],\n",
            "        [4.1499],\n",
            "        [5.9886],\n",
            "        [7.8272]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03734365478157997\n",
            "yhat: tensor([[2.3105],\n",
            "        [4.1497],\n",
            "        [5.9889],\n",
            "        [7.8281]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.0371195524930954\n",
            "yhat: tensor([[2.3096],\n",
            "        [4.1494],\n",
            "        [5.9892],\n",
            "        [7.8289]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03689704090356827\n",
            "yhat: tensor([[2.3088],\n",
            "        [4.1491],\n",
            "        [5.9894],\n",
            "        [7.8297]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03667604923248291\n",
            "yhat: tensor([[2.3079],\n",
            "        [4.1488],\n",
            "        [5.9896],\n",
            "        [7.8304]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.036456476897001266\n",
            "yhat: tensor([[2.3071],\n",
            "        [4.1484],\n",
            "        [5.9898],\n",
            "        [7.8311]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.036238327622413635\n",
            "yhat: tensor([[2.3062],\n",
            "        [4.1481],\n",
            "        [5.9899],\n",
            "        [7.8318]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03602154552936554\n",
            "yhat: tensor([[2.3053],\n",
            "        [4.1477],\n",
            "        [5.9901],\n",
            "        [7.8324]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03580609709024429\n",
            "yhat: tensor([[2.3045],\n",
            "        [4.1473],\n",
            "        [5.9902],\n",
            "        [7.8330]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.035591933876276016\n",
            "yhat: tensor([[2.3036],\n",
            "        [4.1469],\n",
            "        [5.9903],\n",
            "        [7.8336]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03537904471158981\n",
            "yhat: tensor([[2.3027],\n",
            "        [4.1465],\n",
            "        [5.9904],\n",
            "        [7.8342]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.035167545080184937\n",
            "yhat: tensor([[2.3018],\n",
            "        [4.1461],\n",
            "        [5.9904],\n",
            "        [7.8348]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.034957241266965866\n",
            "yhat: tensor([[2.3009],\n",
            "        [4.1457],\n",
            "        [5.9905],\n",
            "        [7.8353]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03474821150302887\n",
            "yhat: tensor([[2.3000],\n",
            "        [4.1453],\n",
            "        [5.9906],\n",
            "        [7.8358]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03454046696424484\n",
            "yhat: tensor([[2.2991],\n",
            "        [4.1449],\n",
            "        [5.9906],\n",
            "        [7.8364]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03433392569422722\n",
            "yhat: tensor([[2.2982],\n",
            "        [4.1445],\n",
            "        [5.9907],\n",
            "        [7.8369]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.034128665924072266\n",
            "yhat: tensor([[2.2974],\n",
            "        [4.1440],\n",
            "        [5.9907],\n",
            "        [7.8374]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03392457962036133\n",
            "yhat: tensor([[2.2965],\n",
            "        [4.1436],\n",
            "        [5.9908],\n",
            "        [7.8379]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.033721767365932465\n",
            "yhat: tensor([[2.2956],\n",
            "        [4.1432],\n",
            "        [5.9908],\n",
            "        [7.8384]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.033520180732011795\n",
            "yhat: tensor([[2.2947],\n",
            "        [4.1428],\n",
            "        [5.9908],\n",
            "        [7.8389]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03331972658634186\n",
            "yhat: tensor([[2.2938],\n",
            "        [4.1424],\n",
            "        [5.9909],\n",
            "        [7.8394]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03312058001756668\n",
            "yhat: tensor([[2.2930],\n",
            "        [4.1419],\n",
            "        [5.9909],\n",
            "        [7.8399]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03292250633239746\n",
            "yhat: tensor([[2.2921],\n",
            "        [4.1415],\n",
            "        [5.9910],\n",
            "        [7.8404]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03272565081715584\n",
            "yhat: tensor([[2.2912],\n",
            "        [4.1411],\n",
            "        [5.9910],\n",
            "        [7.8409]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.032530032098293304\n",
            "yhat: tensor([[2.2903],\n",
            "        [4.1407],\n",
            "        [5.9910],\n",
            "        [7.8414]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03233551234006882\n",
            "yhat: tensor([[2.2895],\n",
            "        [4.1403],\n",
            "        [5.9910],\n",
            "        [7.8418]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03214217722415924\n",
            "yhat: tensor([[2.2886],\n",
            "        [4.1398],\n",
            "        [5.9911],\n",
            "        [7.8423]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03195001929998398\n",
            "yhat: tensor([[2.2877],\n",
            "        [4.1394],\n",
            "        [5.9911],\n",
            "        [7.8428]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03175899758934975\n",
            "yhat: tensor([[2.2869],\n",
            "        [4.1390],\n",
            "        [5.9911],\n",
            "        [7.8433]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03156915679574013\n",
            "yhat: tensor([[2.2860],\n",
            "        [4.1386],\n",
            "        [5.9912],\n",
            "        [7.8437]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.031380362808704376\n",
            "yhat: tensor([[2.2852],\n",
            "        [4.1382],\n",
            "        [5.9912],\n",
            "        [7.8442]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.03119276836514473\n",
            "yhat: tensor([[2.2843],\n",
            "        [4.1378],\n",
            "        [5.9912],\n",
            "        [7.8447]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.031006280332803726\n",
            "yhat: tensor([[2.2835],\n",
            "        [4.1374],\n",
            "        [5.9912],\n",
            "        [7.8451]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.030820906162261963\n",
            "yhat: tensor([[2.2826],\n",
            "        [4.1369],\n",
            "        [5.9913],\n",
            "        [7.8456]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.030636632815003395\n",
            "yhat: tensor([[2.2818],\n",
            "        [4.1365],\n",
            "        [5.9913],\n",
            "        [7.8461]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.030453456565737724\n",
            "yhat: tensor([[2.2809],\n",
            "        [4.1361],\n",
            "        [5.9913],\n",
            "        [7.8465]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.0302713792771101\n",
            "yhat: tensor([[2.2801],\n",
            "        [4.1357],\n",
            "        [5.9914],\n",
            "        [7.8470]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.030090387910604477\n",
            "yhat: tensor([[2.2793],\n",
            "        [4.1353],\n",
            "        [5.9914],\n",
            "        [7.8474]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.029910480603575706\n",
            "yhat: tensor([[2.2784],\n",
            "        [4.1349],\n",
            "        [5.9914],\n",
            "        [7.8479]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.02973164990544319\n",
            "yhat: tensor([[2.2776],\n",
            "        [4.1345],\n",
            "        [5.9914],\n",
            "        [7.8484]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.029553892090916634\n",
            "yhat: tensor([[2.2768],\n",
            "        [4.1341],\n",
            "        [5.9915],\n",
            "        [7.8488]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.029377169907093048\n",
            "yhat: tensor([[2.2759],\n",
            "        [4.1337],\n",
            "        [5.9915],\n",
            "        [7.8493]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.029201511293649673\n",
            "yhat: tensor([[2.2751],\n",
            "        [4.1333],\n",
            "        [5.9915],\n",
            "        [7.8497]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.0290269423276186\n",
            "yhat: tensor([[2.2743],\n",
            "        [4.1329],\n",
            "        [5.9915],\n",
            "        [7.8502]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.02885339967906475\n",
            "yhat: tensor([[2.2735],\n",
            "        [4.1325],\n",
            "        [5.9916],\n",
            "        [7.8506]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.02868090197443962\n",
            "yhat: tensor([[2.2726],\n",
            "        [4.1321],\n",
            "        [5.9916],\n",
            "        [7.8511]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.028509382158517838\n",
            "yhat: tensor([[2.2718],\n",
            "        [4.1317],\n",
            "        [5.9916],\n",
            "        [7.8515]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.028338972479104996\n",
            "yhat: tensor([[2.2710],\n",
            "        [4.1313],\n",
            "        [5.9916],\n",
            "        [7.8520]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.028169553726911545\n",
            "yhat: tensor([[2.2702],\n",
            "        [4.1309],\n",
            "        [5.9917],\n",
            "        [7.8524]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.028001107275485992\n",
            "yhat: tensor([[2.2694],\n",
            "        [4.1305],\n",
            "        [5.9917],\n",
            "        [7.8528]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.02783368155360222\n",
            "yhat: tensor([[2.2686],\n",
            "        [4.1301],\n",
            "        [5.9917],\n",
            "        [7.8533]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.027667280286550522\n",
            "yhat: tensor([[2.2678],\n",
            "        [4.1298],\n",
            "        [5.9917],\n",
            "        [7.8537]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.027501830831170082\n",
            "yhat: tensor([[2.2670],\n",
            "        [4.1294],\n",
            "        [5.9918],\n",
            "        [7.8542]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.027337461709976196\n",
            "yhat: tensor([[2.2662],\n",
            "        [4.1290],\n",
            "        [5.9918],\n",
            "        [7.8546]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.027174025774002075\n",
            "yhat: tensor([[2.2654],\n",
            "        [4.1286],\n",
            "        [5.9918],\n",
            "        [7.8550]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.027011532336473465\n",
            "yhat: tensor([[2.2646],\n",
            "        [4.1282],\n",
            "        [5.9918],\n",
            "        [7.8555]], grad_fn=<AddmmBackward0>)\n",
            "loss: 0.026850039139389992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-JP6ySlwubL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}